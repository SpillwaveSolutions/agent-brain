---
phase: 02-pluggable-providers
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - agent-brain-server/agent_brain_server/storage/vector_store.py
  - agent-brain-server/agent_brain_server/services/indexing_service.py
  - agent-brain-server/agent_brain_server/api/main.py
  - agent-brain-server/tests/unit/storage/test_vector_store_metadata.py
autonomous: true

must_haves:
  truths:
    - "ChromaDB collection stores embedding provider metadata (provider, model, dimensions)"
    - "Startup validates that current config matches existing collection metadata"
    - "Index operations validate dimension compatibility before processing"
    - "ProviderMismatchError is raised on dimension or provider mismatch"
    - "--force flag allows re-indexing with different provider"
  artifacts:
    - path: "agent-brain-server/agent_brain_server/storage/vector_store.py"
      provides: "Embedding metadata storage and validation"
      contains: "get_embedding_metadata"
    - path: "agent-brain-server/agent_brain_server/services/indexing_service.py"
      provides: "Pre-indexing validation"
      contains: "validate_embedding_compatibility"
    - path: "agent-brain-server/agent_brain_server/api/main.py"
      provides: "Startup dimension validation"
      contains: "check_embedding_compatibility"
  key_links:
    - from: "storage/vector_store.py"
      to: "providers/exceptions.py"
      via: "ProviderMismatchError import"
      pattern: "from.*providers.exceptions.*import.*ProviderMismatchError"
---

<objective>
Implement dimension mismatch prevention to ensure embedding providers match indexed data.

Purpose: Prevent silent search quality degradation when users switch embedding providers without re-indexing. ChromaDB accepts any dimension vectors silently, so we must enforce validation at the application layer.

Output: Metadata storage in ChromaDB collection, startup validation, index-time validation, and --force flag for intentional re-indexing.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-pluggable-providers/02-RESEARCH.md
@agent-brain-server/agent_brain_server/storage/vector_store.py
@agent-brain-server/agent_brain_server/services/indexing_service.py
@agent-brain-server/agent_brain_server/api/main.py
@agent-brain-server/agent_brain_server/providers/exceptions.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add embedding metadata model and storage methods to VectorStoreManager</name>
  <files>agent-brain-server/agent_brain_server/storage/vector_store.py</files>
  <action>
1. Add import for ProviderMismatchError and dataclass for EmbeddingMetadata:

```python
from dataclasses import dataclass, asdict
from typing import Any, Optional
from agent_brain_server.providers.exceptions import ProviderMismatchError

@dataclass
class EmbeddingMetadata:
    """Metadata about the embedding provider used for this collection."""
    provider: str
    model: str
    dimensions: int

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for ChromaDB metadata."""
        return asdict(self)

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "EmbeddingMetadata":
        """Create from dictionary (ChromaDB metadata)."""
        return cls(
            provider=data.get("embedding_provider", "unknown"),
            model=data.get("embedding_model", "unknown"),
            dimensions=data.get("embedding_dimensions", 0),
        )
```

2. Add methods to VectorStoreManager class after `initialize()`:

```python
async def get_embedding_metadata(self) -> Optional[EmbeddingMetadata]:
    """Get stored embedding metadata from collection.

    Returns:
        EmbeddingMetadata if collection has metadata, None otherwise.
    """
    if not self.is_initialized or self._collection is None:
        return None

    async with self._lock:
        metadata = self._collection.metadata
        if metadata and "embedding_provider" in metadata:
            return EmbeddingMetadata.from_dict(metadata)
        return None

async def set_embedding_metadata(
    self,
    provider: str,
    model: str,
    dimensions: int,
) -> None:
    """Store embedding metadata in collection.

    Args:
        provider: Embedding provider name (e.g., "openai", "ollama")
        model: Model name (e.g., "text-embedding-3-large")
        dimensions: Embedding vector dimensions
    """
    if not self.is_initialized or self._collection is None:
        raise RuntimeError("Vector store not initialized")

    async with self._lock:
        assert self._client is not None
        # ChromaDB requires recreating collection to update metadata
        # Get existing metadata and merge
        existing_meta = dict(self._collection.metadata or {})
        existing_meta.update({
            "embedding_provider": provider,
            "embedding_model": model,
            "embedding_dimensions": dimensions,
            "hnsw:space": "cosine",
        })

        # Modify collection metadata
        self._collection.modify(metadata=existing_meta)

        logger.info(
            f"Stored embedding metadata: {provider}/{model} "
            f"({dimensions} dimensions)"
        )

def validate_embedding_compatibility(
    self,
    provider: str,
    model: str,
    dimensions: int,
    stored_metadata: Optional[EmbeddingMetadata],
) -> None:
    """Validate current embedding config against stored metadata.

    Args:
        provider: Current provider name
        model: Current model name
        dimensions: Current embedding dimensions
        stored_metadata: Previously stored metadata (or None if new index)

    Raises:
        ProviderMismatchError: If dimensions or provider/model don't match
    """
    if stored_metadata is None:
        return  # New index, no validation needed

    # Check dimension mismatch first (critical)
    if stored_metadata.dimensions != dimensions:
        raise ProviderMismatchError(
            current_provider=provider,
            current_model=model,
            indexed_provider=stored_metadata.provider,
            indexed_model=stored_metadata.model,
        )

    # Check provider/model mismatch (even same dimensions can be incompatible)
    if (stored_metadata.provider != provider or
        stored_metadata.model != model):
        raise ProviderMismatchError(
            current_provider=provider,
            current_model=model,
            indexed_provider=stored_metadata.provider,
            indexed_model=stored_metadata.model,
        )
```

3. Update `initialize()` to preserve existing metadata:

In the `get_or_create_collection` call, the metadata is already being set to `{"hnsw:space": "cosine"}`. No change needed here as we'll set embedding metadata separately after first indexing.
  </action>
  <verify>Run `cd agent-brain-server && poetry run python -c "from agent_brain_server.storage.vector_store import EmbeddingMetadata, VectorStoreManager; m = EmbeddingMetadata('openai', 'text-embedding-3-large', 3072); print(m.to_dict())"` to verify the dataclass works.</verify>
  <done>VectorStoreManager has get_embedding_metadata, set_embedding_metadata, and validate_embedding_compatibility methods.</done>
</task>

<task type="auto">
  <name>Task 2: Add validation to IndexingService before indexing</name>
  <files>agent-brain-server/agent_brain_server/services/indexing_service.py</files>
  <action>
1. Add imports at the top:

```python
from agent_brain_server.providers.exceptions import ProviderMismatchError
from agent_brain_server.storage.vector_store import EmbeddingMetadata
from agent_brain_server.config.provider_config import load_provider_settings
```

2. Add `force` parameter to `start_indexing` method signature:

```python
async def start_indexing(
    self,
    request: IndexRequest,
    progress_callback: Optional[ProgressCallback] = None,
    force: bool = False,
) -> str:
```

3. Add validation before running pipeline in `start_indexing`:

Inside the method, after the lock check but before starting the background task:

```python
# Validate embedding compatibility unless force=True
if not force:
    await self._validate_embedding_compatibility()
```

4. Add the validation method:

```python
async def _validate_embedding_compatibility(self) -> None:
    """Validate current embedding config matches existing index.

    Raises:
        ProviderMismatchError: If provider/model/dimensions don't match
    """
    # Get stored metadata
    stored_metadata = await self.vector_store.get_embedding_metadata()

    if stored_metadata is None:
        # No existing index, no validation needed
        return

    # Get current config
    settings = load_provider_settings()
    current_provider = settings.embedding.provider
    current_model = settings.embedding.model
    current_dimensions = self.embedding_generator.get_embedding_dimensions()

    # Validate
    self.vector_store.validate_embedding_compatibility(
        provider=str(current_provider),
        model=current_model,
        dimensions=current_dimensions,
        stored_metadata=stored_metadata,
    )
```

5. Update `_run_indexing_pipeline` to store metadata after successful indexing:

After the line `await self.vector_store.initialize()` in `_run_indexing_pipeline`, add:

```python
# Get current embedding config for metadata storage
settings = load_provider_settings()
current_provider = str(settings.embedding.provider)
current_model = settings.embedding.model
current_dimensions = self.embedding_generator.get_embedding_dimensions()
```

After successfully storing in vector database (after the batch loop for ChromaDB upserts), add:

```python
# Store embedding metadata for future validation
await self.vector_store.set_embedding_metadata(
    provider=current_provider,
    model=current_model,
    dimensions=current_dimensions,
)
```

6. Update `reset()` method to note that metadata will be cleared:

Add a comment in the reset method:
```python
# Note: Embedding metadata is stored in collection metadata,
# so it will be cleared when collection is reset
```
  </action>
  <verify>Run `cd agent-brain-server && poetry run python -c "from agent_brain_server.services.indexing_service import IndexingService; print('IndexingService imported successfully')"` to verify imports work.</verify>
  <done>IndexingService validates embedding compatibility before indexing and stores metadata after successful indexing.</done>
</task>

<task type="auto">
  <name>Task 3: Add startup validation to FastAPI lifespan</name>
  <files>agent-brain-server/agent_brain_server/api/main.py</files>
  <action>
1. Add import for ProviderMismatchError:

```python
from agent_brain_server.providers.exceptions import ProviderMismatchError
```

2. Add validation function after the imports section:

```python
async def check_embedding_compatibility(
    vector_store: VectorStoreManager,
) -> Optional[str]:
    """Check if current embedding config matches existing index.

    Args:
        vector_store: Initialized vector store manager

    Returns:
        Warning message if mismatch detected, None if compatible
    """
    try:
        stored_metadata = await vector_store.get_embedding_metadata()
        if stored_metadata is None:
            return None  # No existing index

        # Get current config
        provider_settings = load_provider_settings()
        from agent_brain_server.providers.factory import ProviderRegistry

        embedding_provider = ProviderRegistry.get_embedding_provider(
            provider_settings.embedding
        )
        current_dimensions = embedding_provider.get_dimensions()
        current_provider = str(provider_settings.embedding.provider)
        current_model = provider_settings.embedding.model

        # Check for mismatch
        if (stored_metadata.dimensions != current_dimensions or
            stored_metadata.provider != current_provider or
            stored_metadata.model != current_model):
            return (
                f"Embedding provider mismatch: index was created with "
                f"{stored_metadata.provider}/{stored_metadata.model} "
                f"({stored_metadata.dimensions}d), but current config uses "
                f"{current_provider}/{current_model} ({current_dimensions}d). "
                f"Queries may return incorrect results. "
                f"Re-index with --force to update."
            )
        return None
    except Exception as e:
        logger.warning(f"Failed to check embedding compatibility: {e}")
        return None
```

3. Add validation call in lifespan() after vector store initialization:

After the line `logger.info("Vector store initialized")`, add:

```python
# Check embedding compatibility (PROV-07)
embedding_warning = await check_embedding_compatibility(vector_store)
if embedding_warning:
    logger.warning(f"Embedding compatibility: {embedding_warning}")
    # Store warning for health endpoint
    app.state.embedding_warning = embedding_warning
else:
    app.state.embedding_warning = None
```
  </action>
  <verify>Run `cd agent-brain-server && poetry run python -c "from agent_brain_server.api.main import check_embedding_compatibility; print('Function imported successfully')"` to verify the function is importable.</verify>
  <done>Startup checks embedding compatibility and logs warning if mismatch detected.</done>
</task>

<task type="auto">
  <name>Task 4: Add --force flag to CLI index command</name>
  <files>agent-brain-server/agent_brain_server/models/index.py, agent-brain-cli/agent_brain_cli/commands/index.py</files>
  <action>
1. First, check the IndexRequest model in `agent-brain-server/agent_brain_server/models/index.py` and add force field:

```python
class IndexRequest(BaseModel):
    """Request to start indexing operation."""

    folder_path: str
    recursive: bool = True
    include_code: bool = True
    chunk_size: int = 512
    chunk_overlap: int = 50
    generate_summaries: bool = True
    force: bool = Field(
        default=False,
        description="Force re-indexing even if provider has changed",
    )
```

2. Update the CLI index command in `agent-brain-cli/agent_brain_cli/commands/index.py`:

Add the --force option:

```python
@click.option(
    "--force",
    is_flag=True,
    help="Force re-indexing even if embedding provider has changed",
)
```

And update the function signature and request body to include force=force.

3. Update the API router if needed to pass force through to the service.
  </action>
  <verify>Run `cd agent-brain-cli && poetry run agent-brain index --help` to verify --force flag appears in help.</verify>
  <done>CLI index command has --force flag that bypasses provider mismatch validation.</done>
</task>

<task type="auto">
  <name>Task 5: Add unit tests for embedding metadata validation</name>
  <files>agent-brain-server/tests/unit/storage/test_vector_store_metadata.py</files>
  <action>
Create a new test file with comprehensive tests:

```python
"""Tests for embedding metadata storage and validation."""

import pytest
from unittest.mock import AsyncMock, MagicMock, patch

from agent_brain_server.storage.vector_store import (
    EmbeddingMetadata,
    VectorStoreManager,
)
from agent_brain_server.providers.exceptions import ProviderMismatchError


class TestEmbeddingMetadata:
    """Tests for EmbeddingMetadata dataclass."""

    def test_to_dict(self) -> None:
        """Test conversion to dictionary."""
        metadata = EmbeddingMetadata(
            provider="openai",
            model="text-embedding-3-large",
            dimensions=3072,
        )
        result = metadata.to_dict()
        assert result == {
            "provider": "openai",
            "model": "text-embedding-3-large",
            "dimensions": 3072,
        }

    def test_from_dict(self) -> None:
        """Test creation from dictionary."""
        data = {
            "embedding_provider": "ollama",
            "embedding_model": "nomic-embed-text",
            "embedding_dimensions": 768,
        }
        metadata = EmbeddingMetadata.from_dict(data)
        assert metadata.provider == "ollama"
        assert metadata.model == "nomic-embed-text"
        assert metadata.dimensions == 768

    def test_from_dict_missing_keys(self) -> None:
        """Test handling of missing keys."""
        data = {}
        metadata = EmbeddingMetadata.from_dict(data)
        assert metadata.provider == "unknown"
        assert metadata.model == "unknown"
        assert metadata.dimensions == 0


class TestVectorStoreValidation:
    """Tests for embedding validation methods."""

    def test_validate_compatible(self) -> None:
        """Test validation passes when metadata matches."""
        store = VectorStoreManager()
        stored = EmbeddingMetadata("openai", "text-embedding-3-large", 3072)

        # Should not raise
        store.validate_embedding_compatibility(
            provider="openai",
            model="text-embedding-3-large",
            dimensions=3072,
            stored_metadata=stored,
        )

    def test_validate_dimension_mismatch(self) -> None:
        """Test validation fails on dimension mismatch."""
        store = VectorStoreManager()
        stored = EmbeddingMetadata("openai", "text-embedding-3-large", 3072)

        with pytest.raises(ProviderMismatchError) as exc_info:
            store.validate_embedding_compatibility(
                provider="ollama",
                model="nomic-embed-text",
                dimensions=768,
                stored_metadata=stored,
            )

        assert "Provider mismatch" in str(exc_info.value)
        assert "openai" in str(exc_info.value)
        assert "ollama" in str(exc_info.value)

    def test_validate_provider_mismatch_same_dimensions(self) -> None:
        """Test validation fails on provider mismatch even with same dimensions."""
        store = VectorStoreManager()
        # Both Cohere and some Ollama models can have 1024 dimensions
        stored = EmbeddingMetadata("cohere", "embed-english-v3.0", 1024)

        with pytest.raises(ProviderMismatchError):
            store.validate_embedding_compatibility(
                provider="ollama",
                model="mxbai-embed-large",
                dimensions=1024,
                stored_metadata=stored,
            )

    def test_validate_no_stored_metadata(self) -> None:
        """Test validation passes when no metadata exists (new index)."""
        store = VectorStoreManager()

        # Should not raise
        store.validate_embedding_compatibility(
            provider="openai",
            model="text-embedding-3-large",
            dimensions=3072,
            stored_metadata=None,
        )
```
  </action>
  <verify>Run `cd agent-brain-server && poetry run pytest tests/unit/storage/test_vector_store_metadata.py -v` to run the tests.</verify>
  <done>Unit tests cover all validation scenarios including dimension mismatch, provider mismatch, and new index cases.</done>
</task>

</tasks>

<verification>
1. Run `task before-push` from the agent-brain directory to ensure all quality checks pass
2. Verify ProviderMismatchError is raised when dimensions don't match:
   - Create an index with one provider
   - Change config to different provider
   - Attempt to index again (should fail without --force)
3. Verify --force bypasses validation:
   - With mismatched provider, run `agent-brain index /path --force`
   - Should succeed and update metadata
4. Verify startup logs warning when mismatch detected
5. Run full test suite: `poetry run pytest`
</verification>

<success_criteria>
- EmbeddingMetadata dataclass exists with to_dict/from_dict methods
- VectorStoreManager stores embedding metadata in ChromaDB collection
- VectorStoreManager.validate_embedding_compatibility raises ProviderMismatchError on mismatch
- IndexingService validates before indexing (unless force=True)
- IndexingService stores metadata after successful indexing
- FastAPI startup logs warning if embedding mismatch detected
- CLI index command has --force flag
- Unit tests pass with >80% coverage for new code
- `task before-push` passes
</success_criteria>

<output>
After completion, create `.planning/phases/02-pluggable-providers/02-01-SUMMARY.md`
</output>
