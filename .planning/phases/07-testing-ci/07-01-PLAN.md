---
phase: 07-testing-ci
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - agent-brain-server/tests/contract/conftest.py
  - agent-brain-server/tests/contract/test_backend_contract.py
  - agent-brain-server/tests/contract/test_hybrid_search_contract.py
autonomous: true

must_haves:
  truths:
    - "Contract test suite runs all 11 StorageBackendProtocol methods against both ChromaDB and PostgreSQL backends"
    - "ChromaDB contract tests pass with real ChromaDB (tmp_path isolation)"
    - "PostgreSQL contract tests skip gracefully when DATABASE_URL not set"
    - "Hybrid search similarity test validates top-5 overlap >= 60% across backends"
    - "All scores from both backends are normalized 0-1"
  artifacts:
    - path: "agent-brain-server/tests/contract/conftest.py"
      provides: "Backend factory fixtures with parametrization"
      contains: "storage_backend"
    - path: "agent-brain-server/tests/contract/test_backend_contract.py"
      provides: "11 protocol method contract tests"
      contains: "TestStorageBackendContract"
    - path: "agent-brain-server/tests/contract/test_hybrid_search_contract.py"
      provides: "Hybrid search result similarity validation"
      contains: "test_hybrid_search"
  key_links:
    - from: "agent-brain-server/tests/contract/conftest.py"
      to: "agent_brain_server/storage/chroma/backend.py"
      via: "ChromaBackend import and initialization"
      pattern: "ChromaBackend"
    - from: "agent-brain-server/tests/contract/conftest.py"
      to: "agent_brain_server/storage/postgres/backend.py"
      via: "PostgresBackend lazy import with skipif"
      pattern: "PostgresBackend"
    - from: "agent-brain-server/tests/contract/test_backend_contract.py"
      to: "agent_brain_server/storage/protocol.py"
      via: "SearchResult and EmbeddingMetadata type assertions"
      pattern: "SearchResult|EmbeddingMetadata"
---

<objective>
Create parametrized contract tests that validate all 11 StorageBackendProtocol methods produce identical behavior across ChromaDB and PostgreSQL backends, plus a hybrid search similarity test.

Purpose: Contract tests are the core verification mechanism for Phase 7 — they ensure both backends implement the protocol identically, catching regressions and behavior divergence.
Output: 3 test files in tests/contract/ providing full protocol coverage and hybrid search similarity validation.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-testing-ci/07-RESEARCH.md

# Key source files
@agent-brain-server/agent_brain_server/storage/protocol.py
@agent-brain-server/agent_brain_server/storage/factory.py
@agent-brain-server/agent_brain_server/storage/chroma/backend.py
@agent-brain-server/agent_brain_server/storage/postgres/backend.py
@agent-brain-server/agent_brain_server/storage/postgres/config.py
@agent-brain-server/tests/conftest.py
@agent-brain-server/tests/contract/test_query_modes.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Contract test fixtures with backend parametrization</name>
  <files>agent-brain-server/tests/contract/conftest.py</files>
  <action>
Replace the existing minimal conftest.py in tests/contract/ with a full backend factory fixture module.

Create these fixtures:

1. `chroma_backend` fixture (async):
   - Import ChromaBackend from agent_brain_server.storage.chroma.backend
   - Create ChromaBackend with a fresh VectorStoreManager using tmp_path for persist_directory
   - Also create a BM25IndexManager with state_dir pointing to tmp_path
   - Pass both to ChromaBackend(vector_store=vs, bm25_manager=bm25)
   - Call `await backend.initialize()` (this initializes the underlying ChromaDB collection)
   - Yield the backend
   - Teardown: call `await backend.reset()`

   IMPORTANT: ChromaBackend.__init__ accepts optional vector_store and bm25_manager params.
   VectorStoreManager needs persist_directory set before initialize. Look at the existing
   tests/unit/storage/test_chroma_backend.py for how it mocks — but here we use REAL ChromaDB
   with tmp_path for isolation. Use `VectorStoreManager()` then set `vs.persist_directory = str(tmp_path / "chroma")`.
   For BM25: `BM25IndexManager()` then set `bm25.state_dir = str(tmp_path / "bm25")`.

2. `postgres_backend` fixture (async):
   - Use `pytest.importorskip("asyncpg")` to skip if asyncpg not installed
   - Check `os.environ.get("DATABASE_URL")` — if not set, call `pytest.skip("DATABASE_URL not set")`
   - Import PostgresConfig, PostgresBackend from agent_brain_server.storage.postgres
   - Create config via `PostgresConfig.from_database_url(os.environ["DATABASE_URL"])`
   - Create `PostgresBackend(config=config)`
   - Call `await backend.initialize()`
   - Yield backend
   - Teardown: `await backend.reset()` then `await backend.close()`

3. `storage_backend` fixture (async, params=["chroma", "postgres"]):
   - Uses `request.param` to select which backend
   - For "chroma": use the chroma_backend fixture (pass tmp_path)
   - For "postgres": use the postgres_backend fixture (with skip logic)
   - This is the main fixture contract tests use

   Implementation approach: Use `@pytest.fixture(params=["chroma", "postgres"])` and inside
   the fixture body, create the appropriate backend directly (not via sub-fixtures, which
   causes issues with async parametrization). Inline the creation logic for each backend type.

4. Helper function `_postgres_available() -> bool`:
   - Try `import asyncpg` — if ImportError, return False
   - Check `os.environ.get("DATABASE_URL")` — if not set, return False
   - Return True

Ensure `asyncio_mode = "auto"` from pyproject.toml covers all async fixtures. Add appropriate
type hints. Use `from __future__ import annotations` for forward references.

Do NOT import the global conftest.py fixtures — contract tests should be self-contained with
their own fixtures to avoid singleton contamination. However, the global `reset_singletons`
autouse fixture will still apply (it's autouse=True in the parent conftest.py).
  </action>
  <verify>
Run `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run python -c "from tests.contract.conftest import *; print('conftest imports OK')"` to verify imports.
Run `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/contract/conftest.py --collect-only 2>&1 | head -20` to verify fixture collection.
  </verify>
  <done>conftest.py exists with chroma_backend, postgres_backend, and storage_backend fixtures. Fixtures import without error. ChromaDB fixtures use real ChromaDB with tmp_path. PostgreSQL fixtures skip when DATABASE_URL not set.</done>
</task>

<task type="auto">
  <name>Task 2: Protocol contract tests for all 11 StorageBackendProtocol methods</name>
  <files>agent-brain-server/tests/contract/test_backend_contract.py</files>
  <action>
Create test_backend_contract.py with a TestStorageBackendContract class that tests all 11 protocol methods.

File structure:
- Module docstring explaining contract testing philosophy
- Import SearchResult, EmbeddingMetadata from protocol
- Import pytest

Test class `TestStorageBackendContract` with async methods, each using `storage_backend` fixture:

1. `test_is_initialized` — after fixture setup, `storage_backend.is_initialized` is True
2. `test_upsert_returns_count` — upsert 3 docs, assert returns 3
3. `test_upsert_updates_existing` — upsert doc, upsert same id with different text, get_count still 1
4. `test_vector_search_returns_search_results` — upsert 3 docs with distinct embeddings, search, assert results are SearchResult with 0-1 scores, have chunk_id, text, metadata
5. `test_keyword_search_returns_search_results` — upsert 3 docs with distinct text ("Python programming", "JavaScript development", "Rust systems"), keyword search "Python", assert >= 1 result, all SearchResult, all scores 0-1
6. `test_get_count_empty` — initial count is 0
7. `test_get_count_after_upsert` — upsert 2 docs, count is 2
8. `test_get_by_id_found` — upsert doc with id "test-id-1", get_by_id("test-id-1") returns dict with "text" key
9. `test_get_by_id_not_found` — get_by_id("nonexistent") returns None
10. `test_reset_clears_all_data` — upsert docs, reset, count is 0
11. `test_embedding_metadata_initially_none` — get_embedding_metadata returns None (or EmbeddingMetadata)
12. `test_set_and_get_embedding_metadata` — set_embedding_metadata(provider="openai", model="text-embedding-3-large", dimensions=3072), get returns matching EmbeddingMetadata
13. `test_validate_embedding_compatibility_passes` — create EmbeddingMetadata, validate with same params, no exception
14. `test_validate_embedding_compatibility_fails_dimension` — validate with different dimensions, expect ProviderMismatchError (import from agent_brain_server.config.provider_config)

Use small embedding dimensions for speed: use 8-dimensional embeddings throughout (e.g., [0.1]*8, [0.9]*8, etc.)
WAIT — ChromaDB requires embeddings matching the collection dimension. The ChromaBackend uses VectorStoreManager which creates the collection with whatever dimension the first upsert provides. Use consistent dimensions within each test.

Use 8-dimensional embeddings: `[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]` as the standard test embedding. This avoids 3072-dimension overhead in contract tests.

For vector search tests, use embeddings that are meaningfully different:
- doc1: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
- doc2: [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
- doc3: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
- query: [0.9, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (should rank doc1 first)

Each test must:
- Use `storage_backend` fixture (runs against both chroma and postgres)
- Be async (pytest-asyncio auto mode handles this)
- Assert protocol-level behavior, NOT implementation-specific behavior
- Use reasonable timeouts for CI execution

Add `pytestmark = pytest.mark.asyncio` at module level (though auto mode should handle it).

NOTE on keyword search: ChromaDB's BM25 and PostgreSQL's tsvector have different scoring. The contract test should assert structural correctness (returns SearchResult list, scores in 0-1 range, results non-empty for known matching text) — NOT exact score values or exact ranking.

NOTE on get_by_id: The return type is `dict[str, Any] | None`. Check it returns a dict with at minimum a "text" key for a found document.
  </action>
  <verify>
Run `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/contract/test_backend_contract.py -v -k "chroma" --no-header 2>&1 | tail -30` to verify ChromaDB contract tests pass.
Run `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/contract/test_backend_contract.py -v -k "postgres" --no-header 2>&1 | tail -10` to verify PostgreSQL tests skip gracefully.
  </verify>
  <done>14 contract tests exist covering all 11 protocol methods. ChromaDB parametrization passes (real ChromaDB with tmp_path). PostgreSQL parametrization skips with clear reason when DATABASE_URL not set. All assertions verify protocol-level behavior (SearchResult types, 0-1 scores, correct counts).</done>
</task>

<task type="auto">
  <name>Task 3: Hybrid search result similarity contract test</name>
  <files>agent-brain-server/tests/contract/test_hybrid_search_contract.py</files>
  <action>
Create test_hybrid_search_contract.py that validates hybrid search produces "similar" top-5 results across both backends.

This test is conceptually different from the protocol contract tests — it validates that the same query against the same data produces comparable (not identical) results. Since hybrid search combines vector + keyword results via RRF fusion, the backends use different keyword scoring (BM25 vs tsvector), so exact match is unreasonable.

Approach: Run the test separately against each backend via the parametrized `storage_backend` fixture. Each parametrization independently validates that hybrid search works and returns reasonable results. The cross-backend comparison (Jaccard similarity) is a SEPARATE test that only runs when BOTH backends are available.

Test structure:

1. `test_hybrid_search_returns_results(storage_backend)`:
   - Seed 5 documents with distinct text and 8-dim embeddings
   - Perform vector_search with query embedding
   - Assert results are non-empty, all SearchResult, all scores 0-1
   - This runs against both backends via parametrization

2. `test_keyword_search_returns_relevant_results(storage_backend)`:
   - Seed 5 documents with distinct text: "Python programming language", "FastAPI web framework", "PostgreSQL database system", "ChromaDB vector store", "pytest testing framework"
   - Keyword search "Python programming"
   - Assert at least 1 result, top result text contains "Python"

3. `test_hybrid_search_cross_backend_similarity`:
   - This test is NOT parametrized — it explicitly creates BOTH backends
   - Mark with `@pytest.mark.postgres` and skipif for DATABASE_URL
   - Also skipif asyncpg not importable
   - Create both backends, seed identical data, run same queries
   - Collect top-5 chunk_ids from each
   - Compute Jaccard similarity: `len(set_a & set_b) / len(set_a | set_b)`
   - Assert similarity >= 0.6 (60% overlap threshold)
   - Use the chroma_backend and postgres_backend fixtures from conftest directly

   IMPORTANT: This test only runs when PostgreSQL IS available. When PostgreSQL is not available, it skips. This means locally without PostgreSQL, only the individual backend tests run (chroma passes, postgres skips). In CI with PostgreSQL, all tests run including the cross-backend comparison.

Use Jaccard similarity (set overlap), NOT Spearman correlation — avoids scipy dependency, simpler, sufficient for "similar top-5" requirement per research recommendation.

Add appropriate docstrings explaining the testing philosophy and the 60% threshold rationale.
  </action>
  <verify>
Run `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/contract/test_hybrid_search_contract.py -v -k "chroma" --no-header 2>&1 | tail -15` to verify ChromaDB hybrid search tests pass.
Run `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/contract/test_hybrid_search_contract.py -v -k "postgres" --no-header 2>&1 | tail -10` to verify PostgreSQL tests skip.
Run `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/contract/ -v --no-header 2>&1 | tail -30` to verify all contract tests together.
  </verify>
  <done>Hybrid search contract tests exist. Individual backend tests verify structural correctness (SearchResult types, scores, non-empty results). Cross-backend similarity test exists (marked postgres, skips without DATABASE_URL) using Jaccard similarity with 60% threshold. All ChromaDB tests pass. PostgreSQL tests skip gracefully without database.</done>
</task>

</tasks>

<verification>
1. `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/contract/ -v --no-header` — all contract tests pass (chroma) or skip (postgres)
2. `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/contract/ -v --no-header 2>&1 | grep -c "PASSED"` — at least 15 tests pass (14 contract + hybrid search chroma tests)
3. `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/contract/ -v --no-header 2>&1 | grep "SKIP"` — postgres tests show skip reason
4. `cd /Users/richardhightower/clients/spillwave/src/agent-brain && task before-push` — full quality gate passes (no regressions)
</verification>

<success_criteria>
- All 11 StorageBackendProtocol methods have contract tests
- ChromaDB contract tests pass with real ChromaDB (tmp_path isolation)
- PostgreSQL contract tests skip gracefully when DATABASE_URL not set
- Hybrid search similarity test exists with 60% Jaccard threshold
- `task before-push` passes without PostgreSQL installed
- No regressions in existing 654 tests
</success_criteria>

<output>
After completion, create `.planning/phases/07-testing-ci/07-01-SUMMARY.md`
</output>
