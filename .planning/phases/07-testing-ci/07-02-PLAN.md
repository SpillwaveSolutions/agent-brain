---
phase: 07-testing-ci
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - agent-brain-server/tests/load/__init__.py
  - agent-brain-server/tests/load/test_postgres_pool.py
  - .github/workflows/pr-qa-gate.yml
autonomous: true

must_haves:
  truths:
    - "Load test validates 50 concurrent queries plus background indexing without connection pool exhaustion"
    - "Load test is marked @pytest.mark.postgres and @pytest.mark.slow and skips without DATABASE_URL"
    - "GitHub Actions CI runs PostgreSQL tests via pgvector service container"
    - "CI installs poetry extras [postgres] when PostgreSQL service is available"
    - "task before-push passes without PostgreSQL installed (all postgres-marked tests skip)"
  artifacts:
    - path: "agent-brain-server/tests/load/__init__.py"
      provides: "Load test package marker"
      min_lines: 1
    - path: "agent-brain-server/tests/load/test_postgres_pool.py"
      provides: "Connection pool load test with 50 concurrent queries"
      contains: "test_connection_pool_under_load"
    - path: ".github/workflows/pr-qa-gate.yml"
      provides: "CI workflow with PostgreSQL service container"
      contains: "pgvector"
  key_links:
    - from: "agent-brain-server/tests/load/test_postgres_pool.py"
      to: "agent_brain_server/storage/postgres/backend.py"
      via: "PostgresBackend direct instantiation"
      pattern: "PostgresBackend"
    - from: ".github/workflows/pr-qa-gate.yml"
      to: "agent-brain-server/pyproject.toml"
      via: "poetry install --extras postgres"
      pattern: "extras postgres"
---

<objective>
Create connection pool load test, update CI workflow with PostgreSQL service container, and verify `task before-push` works without PostgreSQL.

Purpose: Load testing validates that the PostgreSQL connection pool handles real concurrent workloads without exhaustion. CI integration ensures every PR validates PostgreSQL behavior automatically. The before-push verification ensures developers without PostgreSQL can still contribute.
Output: Load test file, updated CI workflow, verified local development experience.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-testing-ci/07-RESEARCH.md
@.planning/phases/07-testing-ci/07-01-SUMMARY.md

# Key source files
@agent-brain-server/agent_brain_server/storage/postgres/backend.py
@agent-brain-server/agent_brain_server/storage/postgres/config.py
@agent-brain-server/agent_brain_server/storage/postgres/connection.py
@.github/workflows/pr-qa-gate.yml
@agent-brain-server/Taskfile.yml
@agent-brain-server/pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Connection pool load test</name>
  <files>agent-brain-server/tests/load/__init__.py, agent-brain-server/tests/load/test_postgres_pool.py</files>
  <action>
Create the tests/load/ directory with __init__.py and test_postgres_pool.py.

__init__.py: empty file (just a docstring: """Load and stress tests for storage backends.""")

test_postgres_pool.py structure:

Module-level markers:
```python
import os
import pytest

pytestmark = [
    pytest.mark.postgres,
    pytest.mark.slow,
    pytest.mark.skipif(
        "DATABASE_URL" not in os.environ,
        reason="DATABASE_URL required for PostgreSQL load tests"
    ),
]
```

Also skipif asyncpg not importable — use a try/except at module level:
```python
try:
    import asyncpg  # noqa: F401
    HAS_ASYNCPG = True
except ImportError:
    HAS_ASYNCPG = False

pytestmark = [
    pytest.mark.postgres,
    pytest.mark.slow,
    pytest.mark.skipif(not HAS_ASYNCPG, reason="asyncpg not installed"),
    pytest.mark.skipif("DATABASE_URL" not in os.environ, reason="DATABASE_URL required"),
]
```

Test function: `async def test_connection_pool_under_load()`:
1. Import PostgresConfig, PostgresBackend from agent_brain_server.storage.postgres
2. Create config from DATABASE_URL: `PostgresConfig.from_database_url(os.environ["DATABASE_URL"])`
3. Create backend: `PostgresBackend(config=config)`
4. Initialize: `await backend.initialize()`
5. Seed 100 test documents with 8-dim embeddings:
   - ids: [f"load_doc_{i}" for i in range(100)]
   - embeddings: [[float(i % 8) / 8.0 + 0.1] * 8 for i in range(100)]
   - documents: [f"Load test document number {i} about topic {i % 10}" for i in range(100)]
   - metadatas: [{"idx": i, "topic": f"topic_{i % 10}"} for i in range(100)]
6. Define async query_task(task_id: int):
   - query_embedding = [0.5] * 8
   - results = await backend.vector_search(query_embedding=query_embedding, top_k=5, similarity_threshold=0.0)
   - assert len(results) > 0, f"Query {task_id} returned no results"
   - return task_id
7. Define async background_indexing_task():
   - Loop 10 times: upsert 1 doc each iteration with unique id f"bg_{i}"
   - await asyncio.sleep(0.05) between iterations to simulate processing
8. Create 50 query tasks + 1 background indexing task
9. Run all with asyncio.gather(*query_tasks, bg_task, return_exceptions=True)
10. Check results: count exceptions, assert 0 exceptions
11. Verify pool metrics: `backend.connection_manager.get_pool_metrics()`:
    - assert "pool_size" in metrics (note: pool_size may not be available if using QueuePool — check what get_pool_metrics returns)
    - The key assertion: no exceptions occurred during concurrent operation
12. Cleanup: `await backend.reset()` then `await backend.close()`

Second test: `async def test_connection_pool_metrics_valid()`:
1. Create and initialize PostgresBackend from DATABASE_URL
2. Get pool metrics
3. Assert metrics is a dict with expected keys
4. Assert pool metrics are within reasonable bounds
5. Cleanup

Use import asyncio at top of file. Use type hints throughout.

IMPORTANT: Connection pool default is pool_size=10, pool_max_overflow=10 (from PostgresConfig defaults).
50 concurrent queries with pool of 10+10=20 max connections means queries will queue up waiting
for connections. This is expected behavior — asyncpg handles this with connection queueing.
The test validates that NO TimeoutError or TooManyConnectionsError occurs, meaning the pool
handles the load by queueing requests.
  </action>
  <verify>
Run `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/load/ --collect-only --no-header 2>&1 | tail -10` to verify test collection (should show SKIP or collected).
Run `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/load/ -v --no-header 2>&1 | tail -10` to verify tests skip gracefully without DATABASE_URL.
  </verify>
  <done>Load test directory exists with __init__.py and test_postgres_pool.py. Load test validates 50 concurrent queries + background indexing. Tests marked @pytest.mark.postgres and @pytest.mark.slow. Tests skip gracefully without DATABASE_URL or asyncpg.</done>
</task>

<task type="auto">
  <name>Task 2: Update CI workflow with PostgreSQL service container</name>
  <files>.github/workflows/pr-qa-gate.yml</files>
  <action>
Update the existing pr-qa-gate.yml to add a PostgreSQL service container with pgvector extension.

Changes to make:

1. Add `services` block to the `qa-gate` job (after `environment: ci-testing`, before `steps:`):

```yaml
    services:
      postgres:
        image: pgvector/pgvector:pg16
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: agent_brain_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
```

CRITICAL: Use `pgvector/pgvector:pg16` NOT `postgres:14`. The pgvector image includes the
vector extension needed for `CREATE EXTENSION vector`. Without it, PostgresSchemaManager.initialize()
will fail when it tries to create the extension.

2. Update the server install step to include postgres extras:

Change the "Install server from local build" step. After `poetry install`, add:
```yaml
      - name: Install server dependencies (with PostgreSQL extras)
        run: |
          cd agent-brain-server
          poetry install --extras postgres
```

Actually, better approach: modify the existing "Install server from local build" step to install
with extras. Replace:
```yaml
      - name: Install server from local build
        run: |
          cd agent-brain-server
          poetry install
```
With:
```yaml
      - name: Install server from local build
        run: |
          cd agent-brain-server
          poetry install --extras postgres
```

3. Add DATABASE_URL to the server test step environment:

Update the "Run tests with coverage (Server)" step to include DATABASE_URL:
```yaml
      - name: Run tests with coverage (Server)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          COHERE_API_KEY: ${{ secrets.COHERE_API_KEY }}
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/agent_brain_test
        run: task server:pr-qa-gate
```

4. Add a comment block before the services section explaining the purpose:

```yaml
    # PostgreSQL service container with pgvector for contract + load tests
    # Tests marked @pytest.mark.postgres skip without DATABASE_URL locally
    # but run in CI with this service container providing the database
```

5. Update the cache key for the server venv to include the extras:

Update the existing server venv cache key from:
```yaml
          key: server-venv-${{ runner.os }}-${{ hashFiles('agent-brain-server/poetry.lock') }}
```
To:
```yaml
          key: server-venv-postgres-${{ runner.os }}-${{ hashFiles('agent-brain-server/poetry.lock') }}
```

This ensures a cache miss when transitioning from non-postgres to postgres extras, preventing
stale venvs that lack asyncpg.

Do NOT change anything about the CLI steps — CLI does not use PostgreSQL.
Do NOT add a separate test step for postgres-only tests — the existing test step runs ALL tests,
and postgres-marked tests now run because DATABASE_URL is set.
  </action>
  <verify>
Verify the YAML is valid: `cd /Users/richardhightower/clients/spillwave/src/agent-brain && python -c "import yaml; yaml.safe_load(open('.github/workflows/pr-qa-gate.yml')); print('YAML valid')"`.
Verify the pgvector image is specified: grep for "pgvector" in the file.
Verify DATABASE_URL is set: grep for "DATABASE_URL" in the file.
Verify postgres extras are installed: grep for "extras postgres" in the file.
  </verify>
  <done>CI workflow updated with pgvector/pgvector:pg16 service container, DATABASE_URL env var for server tests, poetry install --extras postgres, health check configuration. YAML is syntactically valid.</done>
</task>

<task type="auto">
  <name>Task 3: Verify task before-push passes without PostgreSQL</name>
  <files></files>
  <action>
Run `task before-push` from the project root to verify the full quality gate passes without PostgreSQL installed.

This is a verification-only task — no files to create or modify. The purpose is to confirm that:

1. All postgres-marked tests skip (not fail) when DATABASE_URL is not set
2. All existing 654 tests still pass
3. New contract tests (chroma parametrization) pass
4. New load tests skip gracefully
5. Black formatting passes for all new test files
6. Ruff linting passes for all new test files
7. mypy type checking passes for all new test files
8. Coverage remains above 50%

Steps:
1. Ensure DATABASE_URL is NOT set in current shell (unset it if present)
2. Run `cd /Users/richardhightower/clients/spillwave/src/agent-brain && task before-push`
3. Verify exit code 0
4. Check output for: no FAILED tests, some SKIPPED tests (postgres), PASSED count >= 654 (existing) + new contract tests

If any failures:
- Black issues: run `task format` and re-run
- Ruff issues: run `task lint:fix` and re-run
- mypy issues: fix type annotations in new test files
- Test failures: debug and fix the failing contract tests
- Coverage drop: ensure new test files contribute to coverage (they test real code paths via ChromaDB)

After verification passes, also run:
- `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/ -v --no-header 2>&1 | grep -c "PASSED"` to count total passed
- `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/ -v --no-header 2>&1 | grep "SKIP"` to list skipped tests
  </action>
  <verify>
`task before-push` exits with code 0.
No test failures in output.
PostgreSQL-marked tests show as SKIPPED with clear reason.
Total passed count >= 654 (no regressions) + new contract tests.
  </verify>
  <done>task before-push passes cleanly without PostgreSQL. All postgres-marked tests skip gracefully. All existing tests pass. All new contract tests (chroma parametrization) pass. Coverage above 50%. Zero regressions.</done>
</task>

</tasks>

<verification>
1. `cd /Users/richardhightower/clients/spillwave/src/agent-brain && task before-push` — exits 0, all checks pass
2. `cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server && poetry run pytest tests/load/ -v --no-header 2>&1 | grep "SKIP"` — load tests skip without PostgreSQL
3. `python -c "import yaml; yaml.safe_load(open('.github/workflows/pr-qa-gate.yml')); print('valid')"` — CI YAML valid
4. `grep "pgvector" .github/workflows/pr-qa-gate.yml` — pgvector image configured
5. `grep "DATABASE_URL" .github/workflows/pr-qa-gate.yml` — DATABASE_URL set in CI env
6. `grep "extras postgres" .github/workflows/pr-qa-gate.yml` — postgres extras installed in CI
</verification>

<success_criteria>
- Load test exists validating 50 concurrent queries + background indexing
- Load test marked @pytest.mark.postgres + @pytest.mark.slow, skips without DATABASE_URL
- CI workflow uses pgvector/pgvector:pg16 service container
- CI workflow sets DATABASE_URL and installs poetry extras [postgres]
- task before-push passes without PostgreSQL (all postgres tests skip, no regressions)
- Total test count >= 654 existing + new contract/load tests
</success_criteria>

<output>
After completion, create `.planning/phases/07-testing-ci/07-02-SUMMARY.md`
</output>
